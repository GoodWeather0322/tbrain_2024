{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_ocr_text(ocr_page):\n",
    "    text_boxes = []\n",
    "\n",
    "    for text_region in ocr_page['information']:\n",
    "        text_boxes +=  text_region['text_list']\n",
    "\n",
    "    THRESHOLD = 20\n",
    "\n",
    "    # 1. 计算每个文本框的 Y 坐标平均值\n",
    "    for box in text_boxes:\n",
    "        y_coords = [box[\"position\"][1], box[\"position\"][3], box[\"position\"][5], box[\"position\"][7]]\n",
    "        box[\"y_avg\"] = np.mean(y_coords)  # 计算 Y 坐标的平均值\n",
    "        box[\"x_min\"] = min(box[\"position\"][0], box[\"position\"][6])  # 计算左上角 X 坐标\n",
    "\n",
    "    # 2. 按 Y 坐标排序\n",
    "    text_boxes = sorted(text_boxes, key=lambda box: box[\"y_avg\"])\n",
    "\n",
    "    # 3. 根据 Y 坐标将文本框分组\n",
    "    lines = []\n",
    "    current_line = [text_boxes[0]]\n",
    "\n",
    "    for box in text_boxes[1:]:\n",
    "        # 判断是否属于同一行，基于 Y 坐标平均值\n",
    "        if abs(box[\"y_avg\"] - current_line[-1][\"y_avg\"]) < THRESHOLD:\n",
    "            current_line.append(box)\n",
    "        else:\n",
    "            # 保存当前行，开启新的一行\n",
    "            lines.append(current_line)\n",
    "            current_line = [box]\n",
    "    lines.append(current_line)  # 添加最后一行\n",
    "\n",
    "    # 4. 对每一行的文本框按 X 坐标排序，并拼接文本内容\n",
    "    result = []\n",
    "    for line in lines:\n",
    "        sorted_line = sorted(line, key=lambda box: box[\"x_min\"])\n",
    "        line_text = ''.join([' '.join(box[\"content\"]) for box in sorted_line])\n",
    "        result.append(line_text)\n",
    "\n",
    "    return '\\n'.join(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_576114/1562737109.py:16: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for pdf_file, ocr_file in tqdm_notebook(list(zip(pdfs, ocrs))):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f74a6c9c8d8460f9676166e394f346b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/643 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pdfplumber\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm_notebook\n",
    "import json\n",
    "import numpy as np\n",
    "import string\n",
    "\n",
    "pdf_folder = Path('/mnt/disk1/goodweather/tbrain_2024/source/競賽資料集/reference/insurance')\n",
    "pdfs = sorted(pdf_folder.glob('*.pdf'))\n",
    "ocr_folder = Path('/mnt/disk1/goodweather/tbrain_2024/AdvancedLiterateMachinery/Applications/DocXChain/output/insurance')\n",
    "ocrs = sorted(ocr_folder.glob('*.json'))\n",
    "\n",
    "refrence_text_folder = Path('/mnt/disk1/goodweather/tbrain_2024/source/競賽資料集/reference_text') / pdf_folder.name\n",
    "refrence_text_folder.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "for pdf_file, ocr_file in tqdm_notebook(list(zip(pdfs, ocrs))):\n",
    "    assert pdf_file.stem == ocr_file.stem\n",
    "    # print(pdf_file.name)\n",
    "    # if pdf_file.stem != '709':\n",
    "    #     continue\n",
    "    text_file = refrence_text_folder / f'{pdf_file.stem}.txt'\n",
    "    texts = []\n",
    "    with pdfplumber.open(pdf_file) as pdf, open(ocr_file, 'r') as f:\n",
    "        ocr_data = json.load(f)\n",
    "        \n",
    "        for i, (page, ocr_page) in enumerate(zip(pdf.pages, ocr_data)):\n",
    "            texts.append(f'**page {i}**')\n",
    "            select_text = None\n",
    "\n",
    "            pdf_page_text = page.extract_text(x_tolerance=3, x_tolerance_ratio=None, y_tolerance=3, layout=False, x_density=7.25, y_density=13)\n",
    "            ocr_page_text = extract_ocr_text(ocr_page)\n",
    "\n",
    "            pdf_page_text_cleaned = pdf_page_text.translate(str.maketrans('', '', string.punctuation + ' 　\\n'))\n",
    "            ocr_page_text_cleaned = ocr_page_text.translate(str.maketrans('', '', string.punctuation + ' 　\\n'))\n",
    "\n",
    "            # print(pdf_page_text_cleaned)\n",
    "            # print(ocr_page_text_cleaned)\n",
    "\n",
    "            assert len(ocr_page_text_cleaned) > 0\n",
    "\n",
    "            if len(pdf_page_text_cleaned) == 0:\n",
    "                select_text = ocr_page_text\n",
    "            elif len(ocr_page_text_cleaned) > 10 and len(pdf_page_text_cleaned) > 10:\n",
    "                select_text = pdf_page_text\n",
    "            elif len(pdf_page_text_cleaned) > 10:\n",
    "                select_text = pdf_page_text\n",
    "            else:\n",
    "                print(pdf_file.stem, i)\n",
    "                print(pdf_page_text_cleaned)\n",
    "                print(ocr_page_text_cleaned)\n",
    "            texts.append(select_text)\n",
    "            texts.append('\\n')\n",
    "    \n",
    "    with open(text_file, 'w') as f:\n",
    "        f.write('\\n'.join(texts))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'question': '什麼是跨境手機掃碼支付?', 'answers': ['允許大陸消費者可以用手機支付寶App在台灣實體商店購買商品或服務']}\n"
     ]
    }
   ],
   "source": [
    "for pid, contents in pid_map_content.items():\n",
    "    for i, content in enumerate(contents):\n",
    "        print(content)\n",
    "        break\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/mnt/disk1/goodweather/tbrain_2024/source/競賽資料集/reference/faq/pid_map_content.json', 'r') as f:\n",
    "    pid_map_content = json.load(f)\n",
    "\n",
    "refrence_text_folder = Path('/mnt/disk1/goodweather/tbrain_2024/source/競賽資料集/reference_text') / 'faq'\n",
    "refrence_text_folder.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "for pid, contents in pid_map_content.items():\n",
    "    text_file = refrence_text_folder / f'{pid}.txt'\n",
    "    texts = []\n",
    "    for i, content in enumerate(contents):\n",
    "        question = content['question']\n",
    "        answers = content['answers']\n",
    "        texts.append(f'**question {i+1}**')\n",
    "        texts.append(question)\n",
    "        texts.append(f'**answer {i+1}**')\n",
    "        texts.append('\\n'.join(answers))\n",
    "        texts.append('\\n')\n",
    "    with open(text_file, 'w') as f:\n",
    "        f.write('\\n'.join(texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "docxchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
