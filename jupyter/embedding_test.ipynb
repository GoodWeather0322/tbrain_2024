{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from FlagEmbedding import BGEM3FlagModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1547f183bc3490b81288044beac40cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 30 files:   0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/tbrain2024/lib/python3.12/site-packages/FlagEmbedding/BGE_M3/modeling.py:335: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  colbert_state_dict = torch.load(os.path.join(model_dir, 'colbert_linear.pt'), map_location='cpu')\n",
      "/opt/anaconda3/envs/tbrain2024/lib/python3.12/site-packages/FlagEmbedding/BGE_M3/modeling.py:336: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  sparse_state_dict = torch.load(os.path.join(model_dir, 'sparse_linear.pt'), map_location='cpu')\n"
     ]
    }
   ],
   "source": [
    "model = BGEM3FlagModel('BAAI/bge-m3', use_fp16=True) # Setting use_fp16 to True speeds up computation with a slight performance degradation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.626  0.3477]\n",
      " [0.35   0.6787]]\n"
     ]
    }
   ],
   "source": [
    "sentences_1 = [\"What is BGE M3?\", \"Defination of BM25\"]\n",
    "sentences_2 = [\"BGE M3 is an embedding model supporting dense retrieval, lexical matching and multi-vector interaction.\", \n",
    "            \"BM25 is a bag-of-words retrieval function that ranks a set of documents based on the query terms appearing in each document\"]\n",
    "\n",
    "embeddings_1 = model.encode(sentences_1, \n",
    "                            batch_size=12, \n",
    "                            max_length=8192, # If you don't need such a long length, you can set a smaller value to speed up the encoding process.\n",
    "                            )['dense_vecs']\n",
    "embeddings_2 = model.encode(sentences_2)['dense_vecs']\n",
    "similarity = embeddings_1 @ embeddings_2.T\n",
    "print(similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'What': np.float16(0.08374), 'is': np.float16(0.08136), 'B': np.float16(0.1298), 'GE': np.float16(0.252), 'M': np.float16(0.1704), '3': np.float16(0.2695), '?': np.float16(0.04092)}\n",
      "{'B': np.float16(0.1411), 'GE': np.float16(0.2588), 'M': np.float16(0.1722), '3': np.float16(0.269), 'is': np.float16(0.1276), 'an': np.float16(0.07336), 'embe': np.float16(0.2142), 'dding': np.float16(0.167), 'model': np.float16(0.255), 'support': np.float16(0.191), 'ing': np.float16(0.08276), 'den': np.float16(0.1815), 'se': np.float16(0.12146), 're': np.float16(0.05713), 'trie': np.float16(0.1576), 'val': np.float16(0.06335), 'lex': np.float16(0.1515), 'ical': np.float16(0.10547), 'match': np.float16(0.1508), 'and': np.float16(0.01593), 'multi': np.float16(0.0843), 've': np.float16(0.1453), 'ctor': np.float16(0.1401), 'interaction': np.float16(0.1527)}\n",
      "0.00877\n"
     ]
    }
   ],
   "source": [
    "sentences_1 = [\"What is BGE M3?\", \"Defination of BM25\"]\n",
    "sentences_2 = [\"BGE M3 is an embedding model supporting dense retrieval, lexical matching and multi-vector interaction.\", \n",
    "               \"BM25 is a bag-of-words retrieval function that ranks a set of documents based on the query terms appearing in each document\"]\n",
    "\n",
    "output_1 = model.encode(sentences_1, return_dense=True, return_sparse=True, return_colbert_vecs=False)\n",
    "output_2 = model.encode(sentences_2, return_dense=True, return_sparse=True, return_colbert_vecs=False)\n",
    "\n",
    "# you can see the weight for each token:\n",
    "print(model.convert_id_to_token(output_1['lexical_weights'][0]))\n",
    "print(model.convert_id_to_token(output_2['lexical_weights'][0]))\n",
    "\n",
    "lexical_scores = model.compute_lexical_matching_score(output_1['lexical_weights'][0], output_2['lexical_weights'][1])\n",
    "print(lexical_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.7799)\n",
      "tensor(0.4622)\n"
     ]
    }
   ],
   "source": [
    "sentences_1 = [\"What is BGE M3?\", \"Defination of BM25\"]\n",
    "sentences_2 = [\"BGE M3 is an embedding model supporting dense retrieval, lexical matching and multi-vector interaction.\", \n",
    "               \"BM25 is a bag-of-words retrieval function that ranks a set of documents based on the query terms appearing in each document\"]\n",
    "\n",
    "output_1 = model.encode(sentences_1, return_dense=True, return_sparse=True, return_colbert_vecs=True)\n",
    "output_2 = model.encode(sentences_2, return_dense=True, return_sparse=True, return_colbert_vecs=True)\n",
    "\n",
    "print(model.colbert_score(output_1['colbert_vecs'][0], output_2['colbert_vecs'][0]))\n",
    "print(model.colbert_score(output_1['colbert_vecs'][0], output_2['colbert_vecs'][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "什麼是跨境手機掃碼支付 允許大陸消費者可以用手機支付寶App在台灣實體商店購買商品或服務\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "def remove_stopwords(text: str):\n",
    "    text = re.sub(r\"\\*\\*page \\d+\\*\\*\", \"\", text)\n",
    "    text = re.sub(r\"\\*\\*question \\d+\\*\\*\", \"\", text)\n",
    "    text = re.sub(r\"\\*\\*answer \\d+\\*\\*\", \"\", text)\n",
    "    # Step 1: 去除網址和 EMAIL\n",
    "    text = re.sub(r\"http\\S+|www\\S+|https\\S+|[\\w\\.-]+@[\\w\\.-]+\", \"\", text)\n",
    "\n",
    "    text = re.sub(r\"【[A-Za-z0-9]+】\", \"\", text)\n",
    "\n",
    "    # Step 6: 去除 \"第 X 頁，共 Y 頁\" 格式\n",
    "    text = re.sub(r\"第 \\d+ 頁，共 \\d+ 頁\", \"\", text)\n",
    "\n",
    "    # Step 7: 去除 \"X/Y\" 或 \"X / Y\" 格式\n",
    "    text = re.sub(r\"\\b\\d+ ?/ ?\\d+\\b\", \"\", text)\n",
    "\n",
    "    # Step 8: 去除 \"~X~\" 格式\n",
    "    text = re.sub(r\"~\\d+~\", \"\", text)\n",
    "\n",
    "    # Step 9: 去除 \"（接次頁）\" 和 \"（承前頁）\"\n",
    "    text = re.sub(r\"（接次頁）|（承前頁）\", \"\", text)\n",
    "\n",
    "    # Step 10: 去除 \"- X -\" 格式\n",
    "    text = re.sub(r\"- \\d+ -\", \"\", text)\n",
    "\n",
    "    # Step 2: 去除無意義數字（可以依需求調整，如果想保留某些數字格式）\n",
    "    text = re.sub(r\"\\b\\d+\\b\", \"\", text)\n",
    "\n",
    "    # Step 3: 去除標點符號\n",
    "    text = re.sub(r\"[^\\w\\s]\", \"\", text)\n",
    "\n",
    "    # 去除多餘的空格\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "\n",
    "    return text\n",
    "\n",
    "with open('../source/競賽資料集/reference_text/faq/0.txt', 'r', encoding='utf-8') as f:\n",
    "    text = f.read()\n",
    "    print(remove_stopwords(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.506  0.6475 0.6294 0.4812 0.618  0.3884 0.3748 0.768  0.4712 0.3342\n",
      " 0.3657 0.3481 0.3606 0.5205 0.4097]\n"
     ]
    }
   ],
   "source": [
    "query = \"提領PayPal款項到玉山銀行的最低金額是多少？\"\n",
    "\n",
    "texts = []\n",
    "for idx in [209, 530, 536, 316, 215, 202, 134, 604, 481, 304, 157, 415, 174, 77, 332]:\n",
    "    with open(f'../source/競賽資料集/reference_text/faq/{idx}.txt', 'r', encoding='utf-8') as f:\n",
    "        text = f.read()\n",
    "        texts.append(remove_stopwords(text))\n",
    "\n",
    "\n",
    "embeddings_1 = model.encode(texts)['dense_vecs']\n",
    "embeddings_2 = model.encode(query)['dense_vecs']\n",
    "similarity = embeddings_1 @ embeddings_2.T\n",
    "print(similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../source/競賽資料集/reference_text/finance/510.txt 9613\n",
      "../source/競賽資料集/reference_text/finance/672.txt 16055\n",
      "../source/競賽資料集/reference_text/finance/471.txt 11074\n",
      "../source/競賽資料集/reference_text/finance/667.txt 9099\n",
      "../source/競賽資料集/reference_text/finance/28.txt 17494\n",
      "../source/競賽資料集/reference_text/finance/507.txt 8444\n",
      "../source/競賽資料集/reference_text/finance/711.txt 12295\n",
      "../source/競賽資料集/reference_text/finance/739.txt 12251\n",
      "../source/競賽資料集/reference_text/finance/117.txt 14167\n",
      "../source/競賽資料集/reference_text/finance/301.txt 14637\n",
      "../source/競賽資料集/reference_text/finance/260.txt 15518\n",
      "../source/競賽資料集/reference_text/finance/106.txt 13979\n",
      "../source/競賽資料集/reference_text/finance/304.txt 11740\n",
      "../source/競賽資料集/reference_text/finance/113.txt 9573\n",
      "../source/競賽資料集/reference_text/finance/107.txt 21322\n",
      "../source/競賽資料集/reference_text/finance/503.txt 11393\n",
      "../source/競賽資料集/reference_text/finance/878.txt 13864\n",
      "../source/競賽資料集/reference_text/finance/925.txt 14251\n",
      "../source/競賽資料集/reference_text/finance/266.txt 16071\n",
      "../source/競賽資料集/reference_text/finance/765.txt 12675\n",
      "../source/競賽資料集/reference_text/finance/76.txt 13439\n",
      "../source/競賽資料集/reference_text/finance/639.txt 9006\n",
      "../source/競賽資料集/reference_text/finance/406.txt 10273\n",
      "../source/競賽資料集/reference_text/finance/604.txt 17140\n",
      "../source/競賽資料集/reference_text/finance/63.txt 14052\n",
      "../source/競賽資料集/reference_text/finance/758.txt 20019\n",
      "../source/競賽資料集/reference_text/finance/228.txt 11581\n",
      "../source/競賽資料集/reference_text/finance/606.txt 18463\n",
      "../source/競賽資料集/reference_text/finance/438.txt 20624\n",
      "../source/競賽資料集/reference_text/finance/439.txt 9332\n",
      "../source/競賽資料集/reference_text/finance/48.txt 11975\n",
      "../source/競賽資料集/reference_text/finance/798.txt 10947\n",
      "../source/競賽資料集/reference_text/finance/217.txt 13034\n",
      "../source/競賽資料集/reference_text/finance/1026.txt 12450\n",
      "../source/競賽資料集/reference_text/finance/763.txt 8571\n",
      "../source/競賽資料集/reference_text/finance/159.txt 19081\n",
      "../source/競賽資料集/reference_text/finance/398.txt 17008\n",
      "../source/競賽資料集/reference_text/finance/359.txt 11848\n",
      "../source/競賽資料集/reference_text/finance/601.txt 14311\n",
      "../source/競賽資料集/reference_text/finance/8.txt 13753\n",
      "../source/競賽資料集/reference_text/finance/787.txt 16198\n",
      "../source/競賽資料集/reference_text/finance/383.txt 14543\n",
      "../source/競賽資料集/reference_text/finance/237.txt 15925\n",
      "../source/競賽資料集/reference_text/finance/430.txt 11719\n",
      "../source/競賽資料集/reference_text/finance/746.txt 13319\n",
      "../source/競賽資料集/reference_text/finance/752.txt 19699\n",
      "../source/競賽資料集/reference_text/finance/587.txt 23974\n",
      "../source/競賽資料集/reference_text/finance/811.txt 12000\n",
      "../source/競賽資料集/reference_text/finance/187.txt 11343\n",
      "../source/競賽資料集/reference_text/finance/79.txt 9206\n",
      "../source/競賽資料集/reference_text/finance/86.txt 18289\n",
      "../source/競賽資料集/reference_text/finance/44.txt 10477\n",
      "../source/競賽資料集/reference_text/finance/596.txt 9337\n",
      "../source/競賽資料集/reference_text/finance/231.txt 11478\n",
      "../source/競賽資料集/reference_text/finance/185.txt 13796\n",
      "../source/競賽資料集/reference_text/finance/1001.txt 10112\n",
      "../source/競賽資料集/reference_text/finance/1015.txt 13486\n",
      "../source/競賽資料集/reference_text/finance/492.txt 9502\n",
      "../source/競賽資料集/reference_text/finance/646.txt 10077\n",
      "../source/競賽資料集/reference_text/finance/35.txt 15146\n",
      "../source/競賽資料集/reference_text/finance/929.txt 16735\n",
      "../source/競賽資料集/reference_text/finance/242.txt 22766\n",
      "../source/競賽資料集/reference_text/finance/532.txt 16624\n",
      "../source/競賽資料集/reference_text/finance/526.txt 17051\n",
      "../source/競賽資料集/reference_text/finance/863.txt 13984\n",
      "../source/競賽資料集/reference_text/finance/651.txt 11223\n",
      "../source/競賽資料集/reference_text/finance/709.txt 19825\n",
      "../source/競賽資料集/reference_text/finance/655.txt 20892\n",
      "../source/競賽資料集/reference_text/finance/720.txt 14477\n",
      "../source/競賽資料集/reference_text/finance/327.txt 14199\n",
      "../source/競賽資料集/reference_text/finance/333.txt 9258\n",
      "../source/競賽資料集/reference_text/finance/723.txt 13729\n",
      "../source/競賽資料集/reference_text/finance/904.txt 9929\n",
      "../source/競賽資料集/reference_text/finance/535.txt 9564\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "cate_folder = Path('../source/競賽資料集/reference_text/finance')\n",
    "for file in cate_folder.glob('*.txt'):\n",
    "    with open(file, 'r', encoding='utf-8') as f:\n",
    "        text = f.read()\n",
    "        text = remove_stopwords(text)\n",
    "\n",
    "    tokens = model.tokenizer.encode(text)\n",
    "    if len(tokens) > 8192:\n",
    "        print(file, len(tokens))\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tbrain2024",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
